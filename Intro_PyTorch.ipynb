{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Intro_PyTorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhishekKaushikCV/AbhishekKaushikCV/blob/main/Intro_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tutorial 2: Introduction to PyTorch\n",
        "- PyTorch is an open source machine learning framework that allows you to write your own neural networks and optimize them efficiently"
      ],
      "metadata": {
        "id": "1tIApjZzM8KD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTz_aChEM6ij"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import math\n",
        "import numpy as np \n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgba\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The basics of PyTorch"
      ],
      "metadata": {
        "id": "1wl3zGJINYJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Using torch:\",torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4rf2E1LOXgr",
        "outputId": "cc768315-0ee3-43e3-a5ad-1ac3d2402371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch: 1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL_soH9hOqmW",
        "outputId": "868632e1-7f5f-4a88-93ff-be96f84ab488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa53284d650>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors: Different functions to create tensors\n",
        "     - torch.Tensor() : allocates memory, and use previous values in memory\n",
        "     - torch.zeros() : creates tensor filled with zeros\n",
        "     - torch.ones() :  creates tensor filled with ones\n",
        "     - torch.rand() : creates tensor with random values Uniformly sampled between 0 and 1\n",
        "     - torch.randn() :  creates tensor with random values from Normal Distribution with 0 mean and 1 Variance\n",
        "     - torch.arange() : creates a tensor containing values N,N+1,N+2 ..., M\n"
      ],
      "metadata": {
        "id": "aqyl3NBaOzSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.Tensor()\n",
        "x = torch.Tensor(2,3,4) # 2 sets with 1 set having 3 rows and 4 columns\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oCz_6R4O1a9",
        "outputId": "d0bf6b20-6626-4d31-8c3b-808739071888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[8.8319e-02, 3.0728e-41, 7.0065e-44, 7.0065e-44],\n",
            "         [6.3058e-44, 6.7262e-44, 7.0065e-44, 6.3058e-44],\n",
            "         [6.8664e-44, 7.2868e-44, 1.1771e-43, 6.8664e-44]],\n",
            "\n",
            "        [[7.9874e-44, 8.1275e-44, 7.0065e-44, 7.2868e-44],\n",
            "         [8.1275e-44, 7.0065e-44, 7.7071e-44, 6.4460e-44],\n",
            "         [7.1466e-44, 7.7071e-44, 7.7071e-44, 7.1466e-44]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2,3,4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWqMTtDLPHEx",
        "outputId": "c97ba4ed-cef1-4667-b84f-3a3e57c20d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,3,4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9VMJ_gqPixm",
        "outputId": "dbd6c0a6-b48a-4a64-d7cd-203351741bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "         [0.9408, 0.1332, 0.9346, 0.5936]],\n",
            "\n",
            "        [[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "         [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "         [0.2696, 0.4414, 0.2969, 0.8317]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2,3,4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Nv4GVxPqDz",
        "outputId": "1b409328-be74-4c25-e719-3663aea95eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.4451,  0.8564,  2.2181,  0.5232],\n",
            "         [ 0.3466, -0.1973, -1.0546,  1.2780],\n",
            "         [ 0.7281, -0.7106, -0.6021,  0.9604]],\n",
            "\n",
            "        [[ 0.4048, -1.3543, -0.4976,  0.4747],\n",
            "         [-0.1976,  1.2683,  1.2243,  0.0981],\n",
            "         [ 1.7423, -1.3527,  0.2191,  0.5526]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1,10)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atdZem52P1KO",
        "outputId": "96b58b7a-f1f1-419e-f429-defcb4296ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the tensor\n",
        "y = x.view(3,3)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBj_lXQzQxuo",
        "outputId": "166034d7-e96a-47e8-cb25-cc64c9ccc3c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape=y.shape\n",
        "print(shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIQAqc26RnMS",
        "outputId": "60ccb279-8c6d-4442-c9aa-30542534017c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape  and size of a tensor\n",
        "shape = x.shape\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "size = x.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = x.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVkQulIrRw52",
        "outputId": "a2d85599-4edd-498a-e802-505d9faa5ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([2, 3, 4])\n",
            "Size: torch.Size([2, 3, 4])\n",
            "Size: 2 3 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor to NumPy and vice-versa"
      ],
      "metadata": {
        "id": "YwO3inOMSGFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_arr = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "np_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR39LxUFSKws",
        "outputId": "cb38eedd-4f89-4a56-ec42-687769bc8b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6],\n",
              "       [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.from_numpy(np_arr)\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqfb5ultSl-d",
        "outputId": "59ba8e63-2290-40fd-d44e-de4c84137ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = tensor.numpy()\n",
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUA_YUR0S1JY",
        "outputId": "97e1d6fc-04dc-4f86-f8d0-0963bfdb4c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6],\n",
              "       [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like `np_arr = tensor.cpu().numpy()`."
      ],
      "metadata": {
        "id": "d72DI_ubTLnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Operations:\n"
      ],
      "metadata": {
        "id": "atvhj6u-VPqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Addition\n",
        "x1 = torch.arange(2,10)\n",
        "x1 = x1.view(2,4)\n",
        "x2 = torch.arange(2,10)\n",
        "x2 = x2.view(2,4)\n",
        "print(x1)\n",
        "print(x2)\n",
        "y = x1 + x2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUK764aTTerM",
        "outputId": "e7c5f37a-26e2-4217-f3d5-50fd89ac2c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 3, 4, 5],\n",
            "        [6, 7, 8, 9]])\n",
            "tensor([[2, 3, 4, 5],\n",
            "        [6, 7, 8, 9]])\n",
            "tensor([[ 4,  6,  8, 10],\n",
            "        [12, 14, 16, 18]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inplace addition\n",
        "x1 = torch.rand(3,3)\n",
        "x2 = torch.rand(3,3)\n",
        "\n",
        "print(x1)\n",
        "print('Before add:',x2)\n",
        "\n",
        "x2.add_(x1) # Underscore postfix in Inplace addition 'x2.add_(x1)'\n",
        "print('After add:',x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peO0P45lV_n9",
        "outputId": "bf64b156-07cf-4e72-a150-902c0c7d5c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4654, 0.1612, 0.1568],\n",
            "        [0.2083, 0.3289, 0.1054],\n",
            "        [0.9192, 0.4008, 0.9302]])\n",
            "Before add: tensor([[0.6558, 0.0766, 0.8460],\n",
            "        [0.3624, 0.3083, 0.0850],\n",
            "        [0.0029, 0.6431, 0.3908]])\n",
            "After add: tensor([[1.1211, 0.2378, 1.0028],\n",
            "        [0.5707, 0.6372, 0.1903],\n",
            "        [0.9222, 1.0438, 1.3210]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the shape of the tensor\n",
        "x = torch.arange(6)\n",
        "print(\"X:\",x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulu5rQITW5LH",
        "outputId": "63fa41d8-ca2d-43d6-c421-733567fe90cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.view(2, 3)\n",
        "print(\"X\", x)\n",
        "print(x.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7JE4vlXXW59",
        "outputId": "e0f2e878-ff99-4cb6-c442-a7924dfe6180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Swapping dimension '0' and '1'\n",
        "x = x.permute(1,0)\n",
        "print(\"X:\",x)\n",
        "print(\"Swapped axes:\",x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLXaOzxjXpdM",
        "outputId": "de745cbf-7f45-4524-d45d-3e61113308e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n",
            "Swapped axes: torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
        "print(\"W\", W)"
      ],
      "metadata": {
        "id": "7AC6iZjex7bB",
        "outputId": "95406742-6aeb-4b59-dccb-471adb95a721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication\n",
        "x = torch.arange(6)\n",
        "x = x.view(2,3)\n",
        "print(\"X:\",x)\n",
        "\n",
        "y = torch.arange(6)\n",
        "y = y.view(3,2)\n",
        "print(\"Y:\",y)\n",
        "\n",
        "p = torch.matmul(x,y)\n",
        "print(\"Product:\",p)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WafnMj0gcITa",
        "outputId": "d67fa161-0608-4f4a-e87a-0835b72c60d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Y: tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "Product: tensor([[10, 13],\n",
            "        [28, 40]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing:"
      ],
      "metadata": {
        "id": "upxKTDNBc00c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(12).view(3,4)\n",
        "print(\"X:\",x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zxb7e2Xc3RL",
        "outputId": "175889a1-d62a-44df-ebfe-0c366dc8e6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,2] # third column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO0T3bNadt_x",
        "outputId": "db14a1f0-6ad8-4182-a16e-b7cab5b3bbeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  6, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0] # first row"
      ],
      "metadata": {
        "id": "Srk39WSm1tsn",
        "outputId": "f67e4d57-aea1-4146-b1ca-3d981586a519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0:2,-1]) # First two rows, last column"
      ],
      "metadata": {
        "id": "47CtJpbR14Mi",
        "outputId": "2bdb68c9-2992-48a7-aa7a-d3fe4f762df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:,1:3]) # Middle two columns"
      ],
      "metadata": {
        "id": "3dxco9-W2W_C",
        "outputId": "565a23c7-d82f-4fc2-dfe0-76c453fef919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2],\n",
            "        [ 5,  6],\n",
            "        [ 9, 10]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic Computation graph and Backpropogation:\n",
        "-  PyTorch is a define-by-run framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way."
      ],
      "metadata": {
        "id": "DWND0Lm86dnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default tensor requires grad = False\n",
        "\n",
        "x = torch.ones((3,))\n",
        "print(x)\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "fKqtVrAP63r5",
        "outputId": "4e4d5a2c-a7f3-48ba-ca46-112a71925a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.])\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change it to gradient tensor\n",
        "\n",
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "NZspJ0ca7PS-",
        "outputId": "786a3d36-8f69-4da8-b246-02ee6b6a8f0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Computaion Graph: \n",
        "\n",
        "### Function: \n",
        "\n",
        "\n",
        "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "-  $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. \n",
        "- For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$. For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
      ],
      "metadata": {
        "id": "Nb99dlvw76GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Only float tensors can have gradients\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "uwm4ukos77Fv",
        "outputId": "da15fa63-8b33-4f2e-9bae-40b8a3e6c640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([0., 1., 2.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Created the computationgraph based on above equation\n",
        "\n",
        "a = x + 2\n",
        "b = a ** 2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "ngbAP_dL9FEe",
        "outputId": "d2efb548-6396-4ed0-dc6c-451974da515f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Backpropogation:\n",
        "\n",
        "- We can perform backpropagation on the computation graph by calling the function `backward()` on the last output, which effectively calculates the gradients for each tensor that has the property `requires_grad=True`:"
      ],
      "metadata": {
        "id": "kDU3G-V_EMSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "gLsRHY179nUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathcal{x}$, and this gradient indicates how a change in $\\mathbf{x}$ will affect output $y$ given the current input $\\mathbf{x}=[0,1,2]$:"
      ],
      "metadata": {
        "id": "cfzdRigXEfIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "metadata": {
        "id": "eCI1mR99Au8f",
        "outputId": "152f7a32-c432-4047-bc91-0843ae22aa23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3333, 2.0000, 2.6667])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU_Support:\n"
      ],
      "metadata": {
        "id": "QTfs1x9UExdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "hwIkmtjoE0sP",
        "outputId": "3bedee31-588f-48f7-b191-e7fb53ebaab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  By default, all tensors we create are stored on the CPU\n",
        "- We can push a tensor to the GPU by using the function `.to(...)`, or `.cuda()`\n",
        "-  Good practice to define a `device` object in your code which points to the GPU if you have one, and otherwise to the CPU"
      ],
      "metadata": {
        "id": "fO9oamlfFVeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "gHP0kditF4JI",
        "outputId": "e5543376-a9cb-4b1f-b210-8d686dd009ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "\n",
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "BwAZ21weGQeu",
        "outputId": "bedd8ddf-6e8b-4d01-9069-7601895d0de5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU version\n",
        "x = x.to(device)\n",
        "# CUDA is asynchronous, so we need to use different timing functions\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ],
      "metadata": {
        "id": "Lsi-erPMGeXG",
        "outputId": "a1606992-940b-4615-9d1b-d2e1e0931da4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 3.20933s\n",
            "GPU time: 0.14917s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU operations have a separate seed we also want to set\n",
        "if torch.cuda.is_available(): \n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    \n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "qIpfeeGPHE_l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}